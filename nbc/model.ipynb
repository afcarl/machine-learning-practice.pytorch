{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "In this exercise, I will implement binary NBCs for solving the Kaggle Cats vs. Dogs dataset.\n",
    "\n",
    "### Data \n",
    "\n",
    "Download the dataset from [here](https://www.kaggle.com/c/dogs-vs-cats/data) and unzip it in a subdirectory called `./data/`.\n",
    "\n",
    "### Model\n",
    "\n",
    "We will use [torchvision](https://pytorch.org/docs/master/torchvision/) pre-trained ResNet to extract features and train an NBC. Since we have real-valued features, we will use a simple Gaussian distribution to represent the class-conditional density $p(x | y = \\text{\\{cat,dog\\}}, \\theta) = \\Pi_{j=1}^D \\mathcal{N}(x_j | \\mu_{jc} , \\sigma_{jc}^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from skimage import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "global_params = {\n",
    "    'batch_size': 1,\n",
    "    'num_workers': 0,\n",
    "    'feature_dim': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsCatsDataset(Dataset):\n",
    "    def __init__(self, is_train, transform):\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        if self.is_train:\n",
    "            self.data_dir = Path(\"data/catdog/train/\")\n",
    "        else:\n",
    "            self.data_dir = Path(\"data/catdog/test1/\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return 25000\n",
    "        else:\n",
    "            return 12500\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            if idx > 12499:\n",
    "                animal = \"dog\"\n",
    "                label = 1\n",
    "            else:\n",
    "                animal = \"cat\"\n",
    "                label = 0\n",
    "            file_name = animal + \".{}.jpg\".format(int(idx % 12500))\n",
    "            img_name = self.data_dir / file_name\n",
    "            img = io.imread(img_name)\n",
    "            img = self.transform(img)\n",
    "            sample = {'image': img, 'label': label}\n",
    "            return sample\n",
    "        else:\n",
    "            img_name = self.data_dir / \"{}.jpg\".format(idx+1)\n",
    "            img = io.imread(img_name)\n",
    "            img = self.transform(img)\n",
    "            sample = {'image': img}\n",
    "            return sample\n",
    "\n",
    "# Resize image to 256x256, then randomly crop to 224x224,\n",
    "# then normalize pixel values\n",
    "dataset = DogsCatsDataset(is_train=True, transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.RandomCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "N = 25000\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "splitpoint = int(0.9 * N)\n",
    "train_idx = indices[:splitpoint]\n",
    "val_idx = indices[splitpoint:]\n",
    "\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "train_loader = DataLoader(dataset, batch_size=global_params['batch_size'],\n",
    "                         sampler=train_sampler, num_workers=global_params['num_workers'])\n",
    "val_loader = DataLoader(dataset, batch_size=global_params['batch_size'],\n",
    "                       sampler=val_sampler, num_workers=global_params['num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run our NBC, lets take a look at applying PCA to the features extracted by the pre-trained resnet18 model, since binary NBC has O(2D) parameters where D is the feature dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4,\n",
    "            resnet.avgpool\n",
    "        ) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out.view(out.size(0), -1)\n",
    "    \n",
    "resnet = ResNet()\n",
    "resnet = resnet.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a 250x512 ndarray,\n",
    "# where dim1 is samples and sim2 is feature dim\n",
    "featurized = []\n",
    "val_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        x = batch['image']\n",
    "        val_labels.append(batch['label'])\n",
    "        x = x.to(gpu)\n",
    "        features = resnet(x)\n",
    "        featurized.append(features.to(cpu))\n",
    "X = torch.stack(featurized).squeeze()\n",
    "val_labels = torch.stack(val_labels).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is a 2500 x 512 torch Tensor that we will now apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "pca.fit(X.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "plt.plot(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try using the top 10 singular values. Now, we can define our NBC and train it with MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNBC(nn.Module):\n",
    "    \"\"\"\n",
    "    An NBC has O(DC) parameters, where \n",
    "    D is the feature dimension and C \n",
    "    is the number of classes.  \n",
    "    \n",
    "    Here, D = feature_dim and C = 2\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim):\n",
    "        super(GaussianNBC, self).__init__()\n",
    "        # mean and variance of the Gaussian for each feature \n",
    "        # dimension of each class\n",
    "        self.feature_dim = feature_dim\n",
    "        # [class, mean, var]\n",
    "        self.params = torch.zeros(2, 2, feature_dim)\n",
    "        # uninformative prior\n",
    "        self.log_priors = torch.log(torch.FloatTensor([0.5])) * torch.ones(2)\n",
    "        self.eps = torch.FloatTensor([1e-6])\n",
    "        self.c = torch.log(torch.FloatTensor([2 * np.pi]))\n",
    "        \n",
    "    def log_normal(self, x, c):\n",
    "        \"\"\"\n",
    "        compute log-likelihood of x, a [feature_dim] vector\n",
    "        under N(x | \\mu_c, \\sigma^2_c)\n",
    "        \n",
    "        returns a feature_dim vector of log-likelihoods\n",
    "        \"\"\"\n",
    "        return (-0.5 * (self.c + torch.log(self.params[c, 1, :]))) + \\\n",
    "                       (-0.5 * (1./(self.params[c, 1, :] + self.eps)) * \\\n",
    "                        ((x - self.params[c, 0, :]) ** 2).float())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: featurized image to classify after training\n",
    "        \"\"\"\n",
    "        preds = self.log_priors\n",
    "        preds[0] = preds[0] + torch.sum(self.log_normal(x, 0))\n",
    "        preds[1] = preds[1] + torch.sum(self.log_normal(x, 1))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c362f8ed5994a8c94584f65e3aa3759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pca_train = PCA(n_components=global_params['feature_dim'], svd_solver='randomized')\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_loader):\n",
    "        x = batch['image']\n",
    "        x = x.to(gpu)\n",
    "        features = resnet(x)\n",
    "        data.append(features.to(cpu))\n",
    "        labels.append(batch['label'])\n",
    "# 22500 x 512\n",
    "data = torch.stack(data).squeeze()\n",
    "# 22500\n",
    "labels = torch.stack(labels).squeeze()\n",
    "# 22500 x feature_dim\n",
    "data_reduced = pca_train.fit_transform(data)\n",
    "data_reduced = torch.from_numpy(data_reduced).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [[-0.0034, -6.9734,  0.8322,  1.9554,  0.2579, -0.1051, -0.2677,\n",
      "         -0.3304, -0.0927,  0.0387],\n",
      "        [ 2.1051,  0.3843,  0.7289,  0.7536,  0.4674,  0.4535,  0.4121,\n",
      "          0.3521,  0.3493,  0.3245]])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0034,  6.9796, -0.8329, -1.9571, -0.2581,  0.1052,  0.2679,\n",
      "          0.3307,  0.0928, -0.0387],\n",
      "        [ 2.0516,  0.5936,  0.9105,  0.5983,  0.7168,  0.5998,  0.5271,\n",
      "          0.4892,  0.3847,  0.3363]])\n"
     ]
    }
   ],
   "source": [
    "# Fit the GaussianNBC with MLE\n",
    "gauss_nbc = GaussianNBC(global_params['feature_dim'])\n",
    "\n",
    "# the MLE estimate for the parameters given the dataset\n",
    "# is just the MLE estimate of a Gaussian in each feature dimension, \n",
    "# i.e., x_hat_j = 1/N sum_i=1 to N (x_j) and \n",
    "# \\sigma^2_hat_j = 1/(N-1) sum_i=1 to N (x_j - x_hat_j) ** 2\n",
    "\n",
    "# select each class using `labels`\n",
    "#data_reduced = torch.from_numpy(data_reduced).float()\n",
    "labels = labels.byte()  \n",
    "flipped_labels = torch.abs(1 - labels)\n",
    "for j in range(global_params['feature_dim']):\n",
    "    gauss_nbc.params[1, 0, j] = torch.mean(data_reduced[labels, j])\n",
    "    gauss_nbc.params[1, 1, j] = torch.var(data_reduced[labels, j])\n",
    "    gauss_nbc.params[0, 0, j] = torch.mean(data_reduced[flipped_labels, j])\n",
    "    gauss_nbc.params[0, 1, j] = torch.var(data_reduced[flipped_labels, j])   \n",
    "    \n",
    "print(gauss_nbc.params[0,:,:10])\n",
    "print(gauss_nbc.params[1,:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1777f98dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_data(d=None, y=None):\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(10), gauss_nbc.params[0,0].numpy(), c='r', label='cat')\n",
    "    plt.scatter(np.arange(10), gauss_nbc.params[1,0].numpy(), c='b', label='dog')\n",
    "    if d is not None and y is not None:\n",
    "        plt.scatter(np.arange(10), d, c='g', label=y)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040424b5953745e3a6870f5a390f9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian NBC training accuracy: 0.5004 %\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "N = 22500\n",
    "labels = labels.long()\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm(range(N)):\n",
    "        x = data_reduced[idx]\n",
    "        y = labels[idx]\n",
    "        _, pred = torch.max(gauss_nbc(x), 0)\n",
    "        if pred == y:\n",
    "            num_correct += 1\n",
    "print(\"Gaussian NBC training accuracy: {} %\".format(num_correct / N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Guassian NBC is not able to do much with this dataset! :( Not too surprising.\n",
    "Just to see what happens, lets train LogReg on the full featurized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = logreg.score(data, labels)\n",
    "print('logreg training accuracy: {} %'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('logreg validation accuracy: {} %'.format(logreg.score(X, val_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset\n",
    "\n",
    "Let's try a simpler dataset so we can get some interesting results out of our Gaussian NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
